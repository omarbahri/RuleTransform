{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skfeature.function.similarity_based import fisher_score\n",
    "\n",
    "from sktime.utils.data_io import load_from_tsfile_to_dataframe\n",
    "from ruletransform import ContractedRuleTransform\n",
    "from ruletransform.utils import get_shapelets_lengths_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'BasicMotions'\n",
    "\n",
    "X_train, y_train = load_from_tsfile_to_dataframe(\n",
    "    os.path.join(os.getcwd(), 'data', name, name + \"_TRAIN.ts\")\n",
    ")\n",
    "X_test, y_test = load_from_tsfile_to_dataframe(\n",
    "        os.path.join(os.getcwd(), 'data', name, name + \"_TEST.ts\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapelet Length Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length, max_length = get_shapelets_lengths_interval(X_train, y_train, total_time=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule Transform Without Shapelet Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Transform Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = ContractedRuleTransform(\n",
    "    shapelet_mining_contract=2,\n",
    "    rule_mining_contract=1,\n",
    "    min_shapelet_length=min_length,\n",
    "    max_shapelet_length=max_length,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "rt.fit(X_train.iloc[:, 0:2], y_train)\n",
    "all_rules_counts = rt.transform(X_train.iloc[:, 0:2], test=False)\n",
    "all_rules_counts_test = rt.transform(X_test.iloc[:, 0:2], test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percentage of rules to keep\n",
    "percentage = 20\n",
    "\n",
    "top_k = int(all_rules_counts.shape[1]*percentage/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indices of rules between inexistant shapelets (flagged -1 supports)\n",
    "to_delete = np.where(np.all(all_rules_counts==-1,axis=1))\n",
    "\n",
    "#Delete the -1 columns\n",
    "all_rules_counts = np.delete(all_rules_counts, to_delete, axis=0)\n",
    "all_rules_counts_test = np.delete(all_rules_counts_test, to_delete, axis=0)\n",
    "\n",
    " #Array to hold the support of each rule\n",
    "supports = np.zeros(all_rules_counts.shape[1], dtype=np.uint16)\n",
    "\n",
    "#Count and store the support of each rule\n",
    "for k in range(all_rules_counts.shape[1]):\n",
    "    supports[k]=all_rules_counts[:,k].sum()\n",
    "\n",
    "#Get indices of rules with highest support\n",
    "best_rules_indices = np.argsort(supports)[::-1][:top_k]\n",
    "\n",
    "#Get the best rules\n",
    "best_rules = all_rules_counts[:,best_rules_indices]\n",
    "best_rules_test = all_rules_counts_test[:,best_rules_indices] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit and Transform a Random Forest Classifier\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=500)\n",
    "clf.fit(best_rules, y_train)\n",
    "y_pred = clf.predict(best_rules_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is: 0.975\n"
     ]
    }
   ],
   "source": [
    "#Compute Test Accuracy\n",
    "print('The test accuracy is: ' + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule Transform With Shapelet Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Transform Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/anaconda3/envs/timeseries/lib/python3.8/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "rt = ContractedRuleTransform(\n",
    "    shapelet_mining_contract=2,\n",
    "    rule_mining_contract=1,\n",
    "    min_shapelet_length=min_length,\n",
    "    max_shapelet_length=max_length,\n",
    "    verbose=0,\n",
    "    clustering_ratio=80\n",
    ")\n",
    "\n",
    "rt.fit(X_train.iloc[:, 0:2], y_train)\n",
    "all_rules_counts = rt.transform(X_train.iloc[:, 0:2], test=False)\n",
    "all_rules_counts_test = rt.transform(X_test.iloc[:, 0:2], test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is: 0.975\n"
     ]
    }
   ],
   "source": [
    "#Fit and Transform a Random Forest Classifier\n",
    "clf = RandomForestClassifier(random_state=0, n_estimators=500)\n",
    "clf.fit(all_rules_counts, y_train)\n",
    "y_pred = clf.predict(all_rules_counts_test)\n",
    "\n",
    "#Compute Test Accuracy\n",
    "print('The test accuracy is: ' + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
